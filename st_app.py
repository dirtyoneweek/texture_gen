# import streamlit as st
# from streamlit_cropper import st_cropper
# from PIL import Image
# st.set_option('deprecation.showfileUploaderEncoding', False)

# # Upload an image and set some options for demo purposes
# st.header("Cropper Demo")
# img_file = st.sidebar.file_uploader(label='Upload a file', type=['png', 'jpg'])
# realtime_update = st.sidebar.checkbox(label="Update in Real Time", value=True)
# box_color = st.sidebar.color_picker(label="Box Color", value='#0000FF')
# aspect_choice = st.sidebar.radio(label="Aspect Ratio", options=["1:1", "16:9", "4:3", "2:3", "Free"])
# aspect_dict = {
#     "1:1": (1, 1),
#     "16:9": (16, 9),
#     "4:3": (4, 3),
#     "2:3": (2, 3),
#     "Free": None
# }
# aspect_ratio = aspect_dict[aspect_choice]

# if img_file:
#     img = Image.open(img_file)
#     if not realtime_update:
#         st.write("Double click to save crop")
#     # Get a cropped image from the frontend
#     cropped_img = st_cropper(img, realtime_update=realtime_update, box_color=box_color,
#                                 aspect_ratio=aspect_ratio)
    
#     # Manipulate cropped image at will
#     st.write("Preview")
#     _ = cropped_img.thumbnail((150,150))
#     st.image(cropped_img)

import torch
from diffusers import StableDiffusionPipeline
from torch import autocast
import streamlit as st
from PIL import Image, ImageEnhance
import pandas as pd
import numpy as np


class StableDiffusionLoader:
    """
    Stable Diffusion loader and generator class. 

    Utilises the stable diffusion models from the `Hugging Face`(https://huggingface.co/spaces/stabilityai/stable-diffusion) library

    Attributes
    ----------
    prompt : str
        a text prompt to use to generate an associated image
    pretrain_pipe : str
        a pretrained image diffusion pipeline i.e. CompVis/stable-diffusion-v1-4

    """
    def __init__(self, 
                prompt:str, 
#                 pretrain_pipe:str='CompVis/stable-diffusion-v1-4'):
                pretrain_pipe:str='runwayml/stable-diffusion-v1-5'):

        """
        Constructs all the necessary attributes for the diffusion class.

        Parameters
        ----------
            prompt : str
                the prompt to generate the model
            pretrain_pipe : str
                the name of the pretrained pipeline
        """
        self.prompt = prompt
        self.pretrain_pipe = pretrain_pipe
        self.device = "cuda" if torch.cuda.is_available() else "cpu"

#         if self.device == 'cpu':
#             raise MemoryError('GPU need for inference')

        assert isinstance(self.prompt, str), 'Please enter a string into the prompt field'
        assert isinstance(self.pretrain_pipe, str), 'Please use value such as `CompVis/stable-diffusion-v1-4` for pretrained pipeline'


    def generate_image_from_prompt(self, save_location='prompt.jpg', use_token=False,
                                   verbose=False):
        """
        Class method to generate images based on the prompt

        Parameters
        ----------
            save_location : str - defaults to prompt.jpg
                the location where to save the image generated by the Diffusion Model
            use_token : bool
                boolean to see if Hugging Face token should be used
            verbose : bool
                boolean that defaults to False, otherwise message printed
        """


        pipe = StableDiffusionPipeline.from_pretrained(
            self.pretrain_pipe, 
            # revision="fp16", 
            # torch_dtype=torch.float16, 
            use_auth_token=use_token,
            safety_checker = None

            )
        pipe = pipe.to(self.device)
        pipe.enable_attention_slicing()

        image = pipe(prompt).images[0]
        image.save(save_location)
        if verbose: 
            print(f'[INFO] saving image to {save_location}')
        return image    

    def __str__(self) -> str:
        return f'[INFO] Generating image for prompt: {self.prompt}'

    def __len__(self):
        return len(self.prompt)

if __name__ == '__main__':


    def patch_conv(cls):
        init = cls.__init__
        def __init__(self, *args, **kwargs):
            if 'padding_mode' not in kwargs:
                kwargs['padding_mode'] = 'circular'
            return init(self, *args, **kwargs)
        cls.__init__ = __init__

    patch_conv(torch.nn.Conv2d)


   
    SAVE_LOCATION = 'prompt.jpg'
    # Create the page title 
#         st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)
    st.title('Image generator using Stable Diffusion')
    st.caption('An app to generate images based on text prompts with a :blue[_Stable Diffusion_] model :sunglasses:')
    # Create a sidebar with text examples
    with st.sidebar:
        # Selectbox
#         st.image('fig/hf.png')
        add_selectbox = st.sidebar.selectbox(
        "Prompt examples",
        (
            "None",
            "Van Gogh painting with squirrels eating nuts", 
            "Homer Simpson on a computer wearing a space suit",
            "Mona Lisa with headphones on",
            "A digital artwork of a roborovski hamster dressed in blue wizards clothing casting a thunderstorm with lightning",
            "A model wearing a scuba diving suit",
            "A looney tunes character driving a car",
            "Optimus Prime on top of a surf board",
            "Albert Einstein with a goofy smile",
            "Nottingham Forest football team lifting the FA Cup"
        ), index=0)
        st.markdown('Use the above drop down box to generate _prompt_ examples')
        st.text('Application by Yizhou Zang')
    
    # Create text prompt
    prompt = st.text_input('Input the prompt desired')
    if add_selectbox != 'None' or prompt is None:
        prompt = add_selectbox

    # Handle if the text box does not have any content in
    if len(prompt) > 0:
        st.markdown(f"""
        This will show an image using **stable diffusion** of the desired {prompt} entered:
        """)
        print(prompt)
        # Create a spinner to show the image is being generated
        with st.spinner('Generating image based on prompt'):
            sd = StableDiffusionLoader(prompt)
            sd.generate_image_from_prompt(save_location=SAVE_LOCATION)
            st.success('Generated stable diffusion model')

        # Open and display the image on the site
        image = Image.open(SAVE_LOCATION)
        st.image(image)  